## Задание "Буферизированный читатель-писатель"

Нам нужно передать данные из некоторого источника некоторому потребителю.
При этом источник отдает данные небольшими пачками (~ десятки записей), а потребитель оптимальнее работает с крупными батчами (~тысячи записей).
Реальный пример - поставка данных из очередей типа Kafka в базу Clickhouse.


### Источник

- Условно бесконечный.
- Источник никогда не возвращает более MaxItems записей за один вызов Next.
- В рамках одной "сессии" (одного вызова функции Pipe) источник каждый раз возвращает новые данные на каждый вызов Next.
- Однако, после перезапуска источник начнет с прошлой "подтвержденной" позиции, задаваемой cookie.
  Поэтому *каждое* значение cookie, которое вернул вызов Next, после сохранения данных в приемнике,
  должно быть фиксировано вызовом Commit, причем строго в той же последовательности, в которой их вернул Next


### Приемник
 
- Не может обработать более MaxItems за один раз.


### Базовый уровень

Требуется реализовать функцию func Pipe(p Producer, c Consumer) error
которая читает данные из источника, группирует их в буфер размером не более MaxItems и сохраняет в приёмник,
после чего фиксирует прогресс в источнике.


### Усложнение

Методы Next, Process и Commit связаны с сетевыми вызовами и могут работать довольно долго.
Для ускорения процесса передачи нужно сделать нужно распараллелить процессы чтения, записи и подтверждения прогресса.
Так, чтобы при вызове Process или Commit продолжалось чтение из источника и формирование нового буфера.


### Шаблон кода

```go
const MaxItems = 9999

type Producer interface {
    // Next returns:
    // - batch of items to be processed
    // - cookie to be commited when processing is done
    // - error
    Next() (items []any, cookie int, err error)
    // Commit is used to mark data batch as processed
    Commit(cookie int) error
}

type Consumer interface {
    Process(items []any) error
}

func Pipe(p Producer, c Consumer) error {
    // TODO
}
```
